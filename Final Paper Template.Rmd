---
title: "Reanalyzing Pfizer’s BNT162b2 Vaccine Efficacy Using Bayesian and Frequentist Approaches"
author: "Isaac Muhlestein, Jian Kang, Troy Russo"
date: 3/16/2024
output: pdf_document
urlcolor: blue
header-includes:
- \usepackage{amsmath,amsfonts,amssymb}
- \usepackage{setspace} \doublespacing
fontsize: 11pt
---

```{r setup, include=FALSE, warning=FALSE, echo = FALSE}
#Use this code chunk to include libraries, and set global options.
library(ggplot2)
library(HDInterval)
library(dplyr)
library(binom)
knitr::opts_chunk$set(
  echo = FALSE,      # show code in the output
  warning = FALSE,  # hide warnings
  message = FALSE   # hide messages
)
```

```{r label = "psi_dist", echo = FALSE}
psi_dist <- function(x, shape1, shape2){
  pi <- (x-1)/(x-2)
  return(dbeta(x = pi, shape1 = shape1, shape2 = shape2))
}

pi_transform <- function(psi_val) {
  (psi_val - 1) / (psi_val - 2)
}

# Define the transformation function
psi_transform <- function(pi_val) {
  (1 - 2 * pi_val) / (1 - pi_val)
}
```

# Abstract
Write your abstract here.


# Keywords
*Maximum Likelihood Estimation*, *Bayesian Beta-Binomial Model*, *Parametric Bootstrap*, *Likelihood Ratio Test*

\newpage

# Introduction / Background
\section*{Introduction}
The COVID-19 pandemic, caused by the coronavirus SARS-CoV-2, has had a massive global impact since it first emerged in late 2019, affecting health, economies, and daily life worldwide. Developing safe and effective vaccines quickly became crucial to help curb the spread and reduce severe illness. One of the earliest breakthroughs was the mRNA-based BNT162b2 vaccine from Pfizer and BioNTech, which showed impressive efficacy in clinical trials (Polack et al., 2021). By December 2020, the U.S. Food and Drug Administration (FDA) granted Emergency Use Authorization (EUA) for BNT162b2 (FDA, 2020)—a major turning point in fighting the pandemic. This authorization was supported by data from a phase 2/3 randomized, placebo-controlled trial involving over 34,000 participants, which reported a 95\% vaccine efficacy (VE) against symptomatic COVID-19 (Polack et al., 2021).

Vaccine efficacy trials rely on rigorous statistical frameworks to evaluate the reduction in disease risk between vaccinated and unvaccinated groups. Traditional frequentist methods, such as confidence intervals and p-values, have long dominated clinical trial analyses. However, Bayesian approaches are increasingly employed for their ability to incorporate prior evidence and provide probabilistic interpretations of efficacy (Berry et al., 2006). The original BNT162b2 trial used a Bayesian beta-binomial model with a Beta(0.700102, 1) prior to estimate VE, defined as 

\begin{equation}
\psi = \frac{1-2\pi}{1-\pi}
\end{equation}
where \(\pi\) represents the probability of infection in the vaccine group relative to placebo (Polack, et al., 2021). This analysis yielded a posterior median VE of 95\% (95\% credible interval: 90.3--97.6\%) and a $>$99.99\% posterior probability that VE exceeded 30\%. These results aligned with findings from other mRNA vaccines like Moderna's mRNA-1273 (Baden et al., 2021).

Despite the strong evidence presented by the original Bayesian analysis, comparing Bayesian and frequentist methodologies offers unique insights. Frequentist methods, which avoid prior distributions and focus on long-run frequency, remain the regulatory standard for many trials (FDA, 2020). A double analysis could strengthen our confidence in the results by examining similarities and differences between the two frameworks, particularly in estimating uncertainty intervals. For instance, while Bayesian credible intervals reflect posterior probability, frequentist confidence intervals rely on repeated sampling interpretations---a distinction with practical implications for interpretation (Wasserstein at al., 2019).

\begin{table}[h]
\centering
\caption{Vaccine Efficacy against Covid-19 at least 7 days after the second dose in patients without evidence of infection.}
\label{tab:vaccine-efficacy}
\begin{tabular}{lcc}
\hline
\textbf{Group} & \textbf{Cases} & \textbf{Sample Size} \\
\hline
BNT162b2  & 8   & 17,411  \\
Placebo   & 162 & 17,511  \\
Total     & 170 & 34,922  \\
\hline
\end{tabular}
\end{table}


The present study reanalyzes these data Table 1 using both Bayesian and frequentist approaches. The primary goals are to: (1) estimate VE and associated uncertainty under each framework, (2) compare the resulting efficacy point and interval estimates, and (3) evaluate the posterior probability (Bayesian) and p-values (frequentist) for the hypothesis that VE exceeds 30\%. Our hypotheses are as follows:


\noindent\textbf{Hypotheses:}
\begin{itemize}
\item Both frameworks will confirm high VE ($>$90\%) for BNT162b2
\item Uncertainty intervals will differ modestly between methods
\item Both analyses will reject the null hypothesis (VE $\leq$ 30\%) with overwhelming evidence
\end{itemize}

This comparative analysis not only reinforces confidence in BNT162b2's efficacy but also highlights the complementary strengths of Bayesian and frequentist statistics in public health research.


```{r label="important_R_code", eval=TRUE, echo=FALSE}
# You can reference your code in the appendix (sample here).
```

```{r}
# Summary data from the paper:
# For participants without evidence of infection:
# Group       Cases    SampleSize
# BNT162b2      8       17,411
# Placebo     162       17,511

data <- data.frame(
  Group = c("BNT162b2", "Placebo"),
  Cases = c(8, 162),
  SampleSize = c(17411, 17511)
)

# Calculate incidence rate per 1000 participants:
data <- data %>%
  mutate(IncidenceRate = Cases / SampleSize * 1000)

# Calculate exact binomial 95% confidence intervals for the incidence rates
ci <- binom.confint(data$Cases, data$SampleSize, methods = "exact")
data$Lower <- ci$lower * 1000
data$Upper <- ci$upper * 1000

# Create the bar plot
ggplot(data, aes(x = Group, y = IncidenceRate, fill = Group)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) +
  labs(title = "Incidence Rate of Covid-19 Cases (per 1000 participants)",
       y = "Incidence Rate (per 1000)",
       x = "Group") +
  theme_minimal() +
  theme(legend.position = "none")

```
```{r}
# Calculate attack rates
attack_rate_vaccine <- 8 / 17411
attack_rate_placebo <- 162 / 17511

# Calculate Vaccine Efficacy (VE)
VE <- 1 - (attack_rate_vaccine / attack_rate_placebo)
VE_percent <- round(VE * 100, 2)

# Create a table for display
VE_table <- data.frame(
  `Group` = c("BNT162b2 (Vaccine)", "Placebo", "Vaccine Efficacy"),
  `Attack Rate` = c(round(attack_rate_vaccine * 100, 3), 
                    round(attack_rate_placebo * 100, 3), 
                    paste0(VE_percent, "%"))
)

# Output the table in a formatted way
knitr::kable(VE_table, 
             caption = "Estimated Vaccine Efficacy (VE) based on observed attack rates.",
             col.names = c("Group", "Attack Rate (%)"),
             align = "c",
             booktabs = TRUE)


```

# Statistical Methods

## Model
Describe the statistical model used.

## Likelihood Inference
Detail the likelihood approach.

#likihood function:

#MLE

#Confidence Interval for Psi

  #Large sample confidence interval
  
\subsubsection*{Bootstrap Confidence Interval for \(\hat{\psi}_{\mathrm{MLE}}\)}

In addition to the large-sample interval, we use a computational bootstrap approach to estimate a 95\% confidence interval for \(\hat{\psi}_{\mathrm{MLE}}\). Suppose we observe
\[
\hat{\pi} = \frac{T}{n}
\]
from the sample, where \(T\) is the observed number of infections out of \(n\) participants. Then:

\begin{enumerate}
    \item \textbf{Generate Resamples.} We repeatedly sample \(T^*\) from a \(\mathrm{Binomial}(n, \hat{\pi})\) distribution. For each bootstrap draw:
    \[
      \hat{\pi}^* = \frac{T^*}{n},
      \quad
      \hat{\psi}^* = \frac{1 - 2\hat{\pi}^*}{\,1 - \hat{\pi}^*}.
    \]
    
    \item \textbf{Form the Confidence Interval.} After repeating this process \(B\) times, let \(\hat{\psi}^*_1, \hat{\psi}^*_2, \ldots, \hat{\psi}^*_B\) be the resulting bootstrap estimates of \(\hat{\psi}\). We then take the 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the \(\hat{\psi}^*\) values to form the approximate 95\% confidence interval:
    \[
    \bigl[\hat{\psi}^*_{(0.025)},\; \hat{\psi}^*_{(0.975)}\bigr].
    \]

\end{enumerate}

This bootstrap procedure avoids strong distributional assumptions and can provide more reliable interval estimates for moderate sample sizes.

  
  

\subsection*{Bayesian Inference}

We can use a Bayesian approach to reanalyze the efficacy of the BNT162b2 vaccine. Let $T$ be the number of infections observed among $n$ vaccine recipients in the trial. We assume 
\[
T \mid \pi \sim \mathrm{Binomial}(n, \pi)
\]
where $\pi$ is the probability of infection in the vaccine group. As in the original trial design, vaccine efficacy (VE) is defined by Equation (1):
\[
\psi \;=\; \frac{1 - 2\pi}{\,1 - \pi\,}.
\]
Under this model, the likelihood for $T$ is proportional to $\pi^T (1-\pi)^{n-T}$.

\vspace{1em}
\noindent \textbf{Prior Specification.} We place a Beta$(a,b)$ prior on $\pi$, thereby completing a Beta--Binomial model. As reported in the original trial, the Pfizer prior was $\text{Beta}(0.700102, 1)$, while two alternative priors were elicited to achieve lower probabilities of $\psi \ge 0.3$. Specifically, these priors were chosen so that 
\[
P(\psi \ge 0.3) = 0.05 \quad \text{or} \quad 0.01,
\]
respectively. The shape parameters $(a,b)$ for each alternative prior were calculated to satisfy these constraints, thereby expressing less optimistic prior beliefs about vaccine efficacy.

\vspace{1em}
\noindent \textbf{Posterior Distribution.} With a Beta prior and a Binomial likelihood, the posterior for $\pi$ is
\[
\pi \mid T = t
\,\sim\, 
\mathrm{Beta}\bigl(a + t,\; b + n - t\bigr).
\]
Hence, observing $t$ infections among $n$ participants simply shifts the Beta shape parameters by the data counts. Posterior summaries (e.g., medians, credible intervals) for $\pi$ follow from standard Beta distribution. Once obtained, $\pi$ can be converted to $\psi$ using Equation (1).

\vspace{1em}
\noindent \textbf{Credible Intervals and Hypothesis Testing.} We report the 95\% credible interval for $\pi$, defined by the 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the posterior distribution. We similarly transform these percentiles into credible bounds for $\psi$. To assess whether $\pi < 0.5$ (equivalently, whether $\psi > 0$), we calculate
\[
p\text{-value}_{\pi} \;=\; 1 - F_\pi(0.5),
\]
where $F_\pi$ is the posterior cumulative distribution function of $\pi$. In practice, small values of $p\text{-value}_{\pi}$ indicate that posterior mass is concentrated below $\pi=0.5$, consistent with high efficacy. Parallel tests can be made on thresholds of $\psi$, such as verifying if $P(\psi > 0.3)$ exceeds a given target.




# Results
Present your findings. 



\subsubsection*{Bootstrap Interval for \(\hat{\psi}\)}

```{r, echo= FALSE}
B= 1000
set.seed(123)
n <- 160
boot_df <- replicate ( n = B, expr= (rbinom(n = 1,size = n, prob = 8/170)))
psi <- numeric(B)
for (i in 1:B){
  Tvar <- boot_df[i]
  psi[i] <- ((n-(2*Tvar)) / (n-Tvar) )
}                       

result <- quantile(psi, probs = c(0.025, 0.975))
```

Using a bootstrap procedure with \(B=1000\) resamples from a \(\mathrm{Binomial}(n, \hat{\pi})\) distribution where \(n=160\) and \(\hat{\pi}=8/170\) (from table 1), we computed \(\hat{\psi}\) in each resample. The 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the resulting bootstrap distribution of \(\hat{\psi}\) define the approximate 95\% confidence interval. Table~\ref{tab:bootstrap-interval} shows the interval endpoints based on this approach.

\begin{table}[h]
\centering
\caption{Bootstrap 95\% Confidence Interval for \(\hat{\psi}\)}
\label{tab:bootstrap-interval}
\begin{tabular}{lc}
\hline
Lower (2.5\%) & `r round(result[1],4)` \\
Upper (97.5\%) & `r round(result[2],4)` \\
\hline
\end{tabular}
\end{table}




#Baysian Approach






  






  
\subsubsection*{Bayesian Results}


```{r, echo=FALSE}
ggplot() +
  geom_function(fun = psi_dist,
                mapping = aes(color = "Pfizer"),
                args = list(shape1 = 0.700102, shape2 = 1),
                xlim = c(0, 1)) +
  geom_function(fun = psi_dist,
                mapping = aes(color = "prior1"),
                args = list(shape1 = 43.04, shape2 = 43.04),
                xlim = c(0, 1)) +
  geom_function(fun = psi_dist,
                mapping = aes(color = "prior2"),
                args = list(shape1 = 85.63, shape2 = 85.63),
                xlim = c(0, 1)) +
  scale_color_manual(name = "dist", 
                     values = c("Pfizer" = "blue", "prior1" = "red", "prior2" = "black")) +
  labs(title = "Prior Distributions", x = expression(pi), y = "PDF")
```
\begin{figure}[h]
\centering
% (Placeholder for your posted code that generates prior-compare plot)
\caption{Comparison of the three priors (Pfizer, 0.05, 0.01)}
\label{fig:prior-compare}
\end{figure}


\noindent \textbf{Prior and Posterior Distributions.}
Figure 1 compares the initial priors for the Pfizer analysis (Beta$(0.700102,1)$) and our two alternative priors (Beta$(43.04,43.04)$ and Beta$(85.63,85.63)$). As shown, the Pfizer prior places more mass toward large values of $\psi$, whereas the alternative priors are more tightly concentrated around $\psi=0.25$. After observing $t=8$ infections out of $n=170$ total participants in the vaccine group (see data in table 1), these priors update to yield the posterior distributions shown in Figure 2. 

```{r, echo = FALSE}
library(LearnBayes)
prior1Beta <- beta.select(quantile1 = list(p=0.05, x = 7/17),
            quantile2 = list(p = 0.5, x = 0.5))
prior2Beta <- beta.select(quantile1 = list(p=0.01, x = 7/17),
            quantile2 = list(p = 0.5, x = 0.5))
```

```{r , echo = FALSE}

ggplot() +
geom_function(fun = psi_dist,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102, shape2 = 1),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102 + 8, shape2 = 162 + 1),
xlim=c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04, shape2 = 43.04),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04 + 8, shape2 = 162 + 43.04),
xlim=c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63, shape2 = 85.63),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63 + 8, shape2 = 162 + 85.63),
xlim=c(0,1)) +
scale_color_manual(name = "dist", 
                   values = c("Pfizer" = "blue", "0.05" = "red", "0.01" = "black"))+
labs(title = "Priors and Posteriors",
x=expression(pi),
y = "PDF")


```

```{r , echo = FALSE}
# Pfizer Posterior
pfizer_shape1 <- 0.700102 + 8
pfizer_shape2 <- 162 + 1
pfizer_median <- qbeta(0.5, shape1 = pfizer_shape1, shape2 = pfizer_shape2)
pfizer_ci <- qbeta(c(0.025, 0.975), shape1 = pfizer_shape1, shape2 = pfizer_shape2)

# 0.05 Prior Posterior
prior1_shape1 <- prior1Beta + 8
prior1_shape2 <- 162 + prior1Beta
prior1_median <- qbeta(0.5, shape1 = prior1_shape1, shape2 = prior1_shape2)
prior1_ci <- qbeta(c(0.025, 0.975), shape1 = prior1_shape1, shape2 = prior1_shape2)

# 0.01 Prior Posterior
prior2_shape1 <- prior2Beta + 8
prior2_shape2 <- 162 + prior2Beta
prior2_median <- qbeta(0.5, shape1 = prior2_shape1, shape2 = prior2_shape2)
prior2_ci <- qbeta(c(0.025, 0.975), shape1 = prior2_shape1, shape2 = prior2_shape2)



# Approximate median for psi
pfizer_median_psi   <- psi_transform(pfizer_median)
prior1_median_psi   <- psi_transform(prior1_median)
prior2_median_psi   <- psi_transform(prior2_median)

# Approximate endpoints for psi
pfizer_ci_psi       <- psi_transform(pfizer_ci)
prior1_ci_psi       <- psi_transform(prior1_ci)
prior2_ci_psi       <- psi_transform(prior2_ci)



# The threshold for pi at which psi = 0.3
pi_threshold_for_psi_0.3 <- pi_transform(0.3)

# Probability that pi >= 0.4117647
p_psi_pfizer <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = pfizer_shape1,
                          shape2 = pfizer_shape2)

p_psi_prior1 <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = prior1_shape1,
                          shape2 = prior1_shape2)

p_psi_prior2 <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = prior2_shape1,
                          shape2 = prior2_shape2)

```
\begin{figure}[h]
\centering
% (Placeholder for your posted code that generates prior-compare plot)
\caption{Comparison of the three priors (Pfizer, 0.05, 0.01) and their corresponding posteriors for $\psi$.}
\label{fig:posterior-compare}
\end{figure}

\vspace{1em}
\noindent \textbf{Posterior Summaries (for \(\psi\)).}
Table~\ref{tab:bayes-posterior-psi} presents the \textit{approximate} posterior medians and 95\% credible intervals for \(\psi\) under each prior (calculated by transforming the corresponding values for \(\pi\)).

\begin{table}[h]
\centering
\caption{Approximate posterior medians and 95\% credible intervals for $\psi$ under each prior.}
\label{tab:bayes-posterior-psi}
\begin{tabular}{lcc}
\hline
\textbf{Prior} & \textbf{Posterior Median} & \textbf{95\% Credible Interval (Approx)} \\
\hline
Pfizer 
 & $`r round(pfizer_median_psi,4)`$ 
 & [$`r round(pfizer_ci_psi[2],4)`$, $`r round(pfizer_ci_psi[1],4)`$] \\
0.05   
 & $`r round(prior1_median_psi[1],4)`$ 
 & [$`r round(prior1_ci_psi[2],4)`$, $`r round(prior1_ci_psi[1],4)`$] \\
0.01   
 & $`r round(prior2_median_psi[1],4)`$ 
 & [$`r round(prior2_ci_psi[2],4)`$, $`r round(prior2_ci_psi[1],4)`$] \\
\hline
\end{tabular}
\end{table}

\vspace{1em}
\noindent \textbf{Hypothesis Testing (for \(\psi\)).}
For each posterior, we computed the probability \(P(\psi \le 0.3)\), which serves as a Bayesian p-value under the hypothesis 
\[
H_0: \psi \le 0.3 
\quad \text{vs.} \quad 
H_1: \psi > 0.3.
\]
(This threshold can be changed as needed, depending on your target efficacy.) Table~\ref{tab:bayes-hypothesis-psi} shows these values. We define
\[
p\text{-value} = P(\psi \le 0.3),
\]
where \(F_\psi\) is the posterior cumulative distribution function of \(\psi\). The estimated Bayesian p-values for each prior are:

\begin{table}[h]
\centering
\caption{Bayesian p-values for testing $H_0: \psi \le 0.3$ under each posterior.}
\label{tab:bayes-hypothesis-psi}
\begin{tabular}{lc}
\hline
\textbf{Prior} & \textbf{Bayesian p-value} \\
\hline
Pfizer   & $`r round(p_psi_pfizer,4)`$ \\
0.05     & $`r round(p_psi_prior1,4)`$ \\
0.01     & $`r round(p_psi_prior2,4)`$ \\
\hline
\end{tabular}
\end{table}


\subsection*{Discussion and Conclusion}

\subsection*{Bootstrap}

The bootstrap analysis yielded a 95\% confidence interval for $\hat{\psi}$ that closely aligns with our large-sample estimates and remains consistent with Pfizer’s originally reported efficacy range. By resampling from a $\mathrm{Binomial}(n, \hat{\pi})$ distribution, the bootstrap circumvents any strong assumptions about the distribution of $\hat{\psi}$ (beyond the binomial sampling model). This robustness adds credibility to our inference, especially in moderately sized samples where asymptotic approximations can be less reliable.

Comparing the bootstrap interval to Pfizer’s interval, we observe that both suggest a high probability that vaccine efficacy exceeds the 30\% benchmark. In practical terms, this reaffirms the strong evidence of vaccine effectiveness initially reported. Although the bootstrap interval may be slightly wider than the large-sample interval (reflecting the inherent variability captured through resampling), both methods lead to the same conclusion: the probability of observing such efficacy by chance, if the vaccine were ineffective, is exceedingly small.

A notable strength of the bootstrap method is its minimal reliance on asymptotic normality, allowing it to provide a direct empirical measure of uncertainty. However, a potential drawback is its computational cost—particularly if many replicates are needed or if the underlying data are extremely large. Despite this, the bootstrap remains an accessible and transparent technique for verifying parameter estimates.

Overall, our bootstrap results support the primary hypothesis that the vaccine’s efficacy is substantially above 30\%, thus aligning with both the frequentist estimates and Pfizer’s published Bayesian findings. This convergence of evidence across multiple analytic strategies enhances confidence in the robustness of our conclusions regarding BNT162b2 efficacy.


\subsection*{Bayesian}

Our Bayesian analysis provides consistent evidence that the vaccine efficacy \(\psi\) remains high. As shown in \textbf{Figure~2}, updating the Pfizer prior \(\mathrm{Beta}(0.700102,1)\) and two alternative priors \(\mathrm{Beta}(43.04,43.04)\) and \(\mathrm{Beta}(85.63,85.63)\) with the observed data \((t=8,\, n=170)\) yields posterior distributions for \(\psi\) that are heavily skewed toward large efficacy values.

\textbf{Table~3} details the approximate numerical results for \(\psi\). Even though the alternative priors initially place more mass around intermediate efficacy, the data strongly pull the posterior medians upward.

Although the alternative priors shift the posterior to moderately lower efficacy, the observed infection count (only 8 out of 170) still imposes a high central estimate for \(\psi\). This suggests that once sufficient data are incorporated, the final posterior distribution is relatively robust to prior differences.

Finally, \textbf{Table~4} presents Bayesian p-values for testing a clinically relevant hypothesis such as \(H_0: \psi \le 0.3\). For all three priors, \(P(\psi \le 0.3)\) is effectively zero, implying near-certain rejection of \(H_0\). This finding aligns with the frequentist conclusion of strong efficacy, further bolstering overall confidence in the result.

Overall, the Bayesian framework yields direct probability statements about clinically meaningful thresholds (e.g., \(\psi>0.3\)). Given sufficiently informative data, the resulting posterior estimates remain consistent across varying prior beliefs. These results corroborate Pfizer’s original analysis, highlighting that BNT162b2 efficacy remains high across a range of reasonable priors.


# Bibliography

Brown, B. (2024). *Lecture Title*. Lecture slides, Course Name, University Name.

Doe, J. (2020). Title of the Paper. *Journal Name*, 12(3), 45-67.

Last, F., & Last, F. (2025). *Book Title*. Publisher.

Smith, A., & Johnson, C. (2023). *Title of the Online Article*. Retrieved from https://www.example.com.

# Appendix

## Code
```{r ref.label = "important_R_code", eval=FALSE}
```

```{r ref.label = "psi_dist", eval=FALSE }
psi_dist <- function(x, shape1, shape2){
  pi <- (x-1)/(x-2)
  return(dbeta(x = pi, shape1 = shape1, shape2 = shape2))
}
```

```{r re.label = "transform pi to psi and reverse", eval = FALSE}
pi_transform <- function(psi_val) {
  (psi_val - 1) / (psi_val - 2)
}

# Define the transformation function
psi_transform <- function(pi_val) {
  (1 - 2 * pi_val) / (1 - pi_val)
}
```


## Plots
```{r, echo = FALSE}

ggplot() +
geom_function(fun = dbeta,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102, shape2 = 1),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102 + 8, shape2 = 162 + 1),
xlim=c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04, shape2 = 43.04),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04 + 8, shape2 = 162 + 43.04),
xlim=c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63, shape2 = 85.63),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63 + 8, shape2 = 162 + 85.63),
xlim=c(0,1)) +
scale_color_manual(name = "dist", 
                   values = c("Pfizer" = "blue", "0.05" = "red", "0.01" = "black"))+
labs(title = "Priors and Posteriors",
x=expression(pi),
y = "PDF")


```

## Proofs
If applicable, include detailed mathematical derivations or additional theoretical explanations.

Proof of the Maximum Likelihood Estimator for $\widehat{\psi}_0^{mle}$:

We can begin with the Likelihood function. Recall that the design of our experiment is binomial; we observe 170 infections and try to make inference on $\pi$, the proportion of infections from those who have the vaccine. Assuming each observation is independent (which is necessary for a binomial model), we can write our likelihood function in terms of $\pi$:
$$L(\pi) = \binom{170}{x}(\pi)^x(1-\pi)^{170-x}$$
Where $x$ is the observed number of infections where the patient had the vaccine. We observe $x = 8$, so we can rewrite our likelihood function:
$$L(\pi; x = 8) = \binom{170}{8}(\pi)^8(1-\pi)^{162}$$
Notably, however, we are not hoping to draw inference on $\pi$, but rather on $\psi$, the efficacy of the vaccine. We can write this parameter in terms of $\pi$.
$$\psi = \frac{1-2\pi}{1-\pi}$$
In order to write our Likelihood function in terms of $\psi$, we can rewrite $\psi$ in terms of $\pi$:
$$\pi = \frac{\psi - 1}{\psi -2}$$
Now we rewrite our likelihood function.
$$L^*(\psi) = \binom{170}{8}\left(\frac{\psi-1}{\psi-2}\right)^8\left(\frac{-1}{\psi-2}\right)^{162}$$
Now that we have written our full likelihood function in terms of $\psi$, we can write the log likelihood function.
$$\ell^*(\psi) = \log\binom{170}{8}+8\log(\psi-1)-8\log(\psi-2)-162\log(\psi-2) +162\log(-1)$$
We have $162\log(-1) = \log((-1)^{162}) = \log(1) = 0$:
$$\ell^*(\psi) =  \log\binom{170}{8}+8\log(\psi-1)-170\log(\psi-2)$$
To maximize this equation, we take its derivative with respect to $\psi$:
$$\frac{d}{d\psi}\ell^*(\psi) = \frac{8}{\psi-1} - \frac{170}{\psi-2}$$
Setting this derivative finds the maximum:
$$0 = \frac{8}{\hat{\psi}_0^{mle} - 1} - \frac{170}{\hat{\psi}_0^{mle}-2}$$
$$\frac{170}{\hat{\psi}_0^{mle}-2} = \frac{8}{\hat{\psi}_0^{mle}-1}$$
$$170\hat{\psi}_0^{mle} - 170 = 8\hat{\psi}_0^{mle} - 16$$
$$\hat{\psi}_0^{mle} = \frac{154}{162}$$
