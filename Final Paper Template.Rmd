---
title: "Reanalyzing Pfizer’s BNT162b2 Vaccine Efficacy Using Bayesian and Frequentist Approaches"
author: "Isaac Muhlestein, Jian Kang, Troy Russo"
date: 3/16/2024
output: pdf_document
urlcolor: blue
header-includes:
- \usepackage{amsmath,amsfonts,amssymb}
- \usepackage{setspace} \doublespacing
- \usepackage{titling}
- \setlength{\droptitle}{-2cm}
- \usepackage{enumitem}

fontsize: 11pt
---

```{r setup, include=FALSE, warning=FALSE, echo = FALSE}
#Use this code chunk to include libraries, and set global options.
library(ggplot2)
library(HDInterval)
library(dplyr)
library(binom)
library(janitor)
library(fastR2)
knitr::opts_chunk$set(
  echo = FALSE,      # show code in the output
  warning = FALSE,  # hide warnings
  message = FALSE   # hide messages
)
```

```{r label = "psi_dist", echo = FALSE}
psi_dist <- function(x, shape1, shape2){
  pi <- (x-1)/(x-2)
  return(dbeta(x = pi, shape1 = shape1, shape2 = shape2))
}

pi_transform <- function(psi_val) {
  (psi_val - 1) / (psi_val - 2)
}

# Define the transformation function
psi_transform <- function(pi_val) {
  (1 - 2 * pi_val) / (1 - pi_val)
}
```


# Abstract
The COVID-19 pandemic emphasized the need for vaccine development, with Pfizer's BNT162b2 mRNA vaccine demonstrating 95\% efficacy in clinical trials. This study reanalyzes the trial data using frequentist and Bayesian frameworks to estimate vaccine efficacy and evaluate hypotheses. Frequentist methods employed maximum likelihood estimation (MLE) and parametric bootstrap confidence intervals, while Bayesian analysis utilized Beta priors to model vaccine efficacy. Both approaches yielded vaccine efficacy estimates exceeding 94.8\%, with Bayesian credible intervals (e.g., 90.3--97.6\% under the original prior) slightly wider than frequentist confidence intervals (94.8--95.3\%). Likelihood ratio and posterior probability tests overwhelmingly rejected the null hypothesis (vaccine efficacy $\leq$ 30\%) with \textit{p}-values $<$ 0.0001. Results confirm BNT162b2's high efficacy and highlight methodological nuances: Bayesian intervals incorporated prior evidence, whereas frequentist methods provided precise, assumption-driven estimates. Despite differing uncertainty quantification, both frameworks strongly supported the vaccine's effectiveness, reinforcing confidence in the vaccine.

# Keywords
*Maximum Likelihood Estimation*, *Bayesian Beta-Binomial Model*, *Parametric Bootstrap*, *Likelihood Ratio Test*


\newpage

# Introduction / Background
The COVID-19 pandemic, caused by the coronavirus SARS-CoV-2, has had a massive global impact since it first emerged in late 2019, affecting health, economies, and daily life worldwide. Developing safe and effective vaccines quickly became crucial to help curb the spread and reduce severe illness. One of the earliest breakthroughs was the mRNA-based BNT162b2 vaccine from Pfizer and BioNTech, which showed impressive efficacy in clinical trials (Polack et al., 2021). By December 2020, the U.S. Food and Drug Administration (FDA) granted Emergency Use Authorization (EUA) for BNT162b2 (FDA, 2020)—a major turning point in fighting the pandemic. This authorization was supported by data from a phase 2/3 randomized, placebo-controlled trial involving over 34,000 participants, which reported a 95\% vaccine efficacy (VE) against symptomatic COVID-19 (Polack et al., 2021).

Vaccine efficacy trials rely on rigorous statistical frameworks to evaluate the reduction in disease risk between vaccinated and unvaccinated groups. Traditional frequentist methods, such as confidence intervals and p-values, have long dominated clinical trial analyses. However, Bayesian approaches are increasingly employed for their ability to incorporate prior evidence and provide probabilistic interpretations of efficacy (Berry et al., 2006). The original BNT162b2 trial used a Bayesian beta-binomial model with a Beta(0.700102, 1) prior to estimate VE, defined as 

\begin{equation}
\psi = \frac{1-2\pi}{1-\pi}
\end{equation}
where \(\pi\) represents the probability of infection in the vaccine group relative to placebo (Polack, et al., 2021). This analysis yielded a posterior median VE of 95\% (95\% credible interval: 90.3--97.6\%) and a $>$99.99\% posterior probability that VE exceeded 30\%. These results aligned with findings from other mRNA vaccines like Moderna's mRNA-1273 (Baden et al., 2021).

Despite the strong evidence presented by the original Bayesian analysis, comparing Bayesian and frequentist methodologies offers unique insights. Frequentist methods, which avoid prior distributions and focus on long-run frequency, remain the regulatory standard for many trials (FDA, 2020). A double analysis could strengthen our confidence in the results by examining similarities and differences between the two frameworks, particularly in estimating uncertainty intervals. For instance, while Bayesian credible intervals reflect posterior probability, frequentist confidence intervals rely on repeated sampling interpretations---a distinction with practical implications for interpretation (Wasserstein at al., 2019).

\begin{table}[h]
\centering
\caption{Vaccine Efficacy against Covid-19 at least 7 days after the second dose in patients without evidence of infection.}
\label{tab:vaccine-efficacy}
\begin{tabular}{lcc}
\hline
\textbf{Group} & \textbf{Cases} & \textbf{Sample Size} \\
\hline
BNT162b2  & 8   & 17,411  \\
Placebo   & 162 & 17,511  \\
Total     & 170 & 34,922  \\
\hline
\end{tabular}
\end{table}

The present study reanalyzes these data Table 1 using both Bayesian and frequentist approaches. The primary goals are to: (1) estimate VE and associated uncertainty under each framework, (2) compare the resulting efficacy point and interval estimates, and (3) evaluate the posterior probability (Bayesian) and p-values (frequentist) for the hypothesis that VE exceeds 30\%. Our hypotheses are as follows:
\begin{itemize}[noitemsep,topsep=0pt]
  \item Both frameworks will confirm high VE ($>90\%$) for BNT162b2
  \item Uncertainty intervals will differ modestly between methods
  \item Both analyses will reject the null hypothesis (VE $\le 0.3$) with overwhelming evidence
\end{itemize}
This comparative analysis not only reinforces confidence in BNT162b2's efficacy but also highlights the complementary strengths of Bayesian and frequentist statistics in public health research.


```{r label="important_R_code", eval=TRUE, echo=FALSE}
# You can reference your code in the appendix (sample here).
```

```{r fig.width=4, fig.height=3, echo=FALSE, fig.align="center"}
# Summary data from the paper:
# For participants without evidence of infection:
# Group       Cases    SampleSize
# BNT162b2      8       17,411
# Placebo     162       17,511

data <- data.frame(
  Group = c("BNT162b2", "Placebo"),
  Cases = c(8, 162),
  SampleSize = c(17411, 17511)
)

# Calculate incidence rate per 1000 participants:
data <- data %>%
  mutate(IncidenceRate = Cases / SampleSize * 1000)

# Calculate exact binomial 95% confidence intervals for the incidence rates
ci <- binom.confint(data$Cases, data$SampleSize, methods = "exact")
data$Lower <- ci$lower * 1000
data$Upper <- ci$upper * 1000

# Create the bar plot
ggplot(data, aes(x = Group, y = IncidenceRate, fill = Group)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) +
  labs(title = "Incidence Rate of Covid-19 Cases (per 1000 participants)",
       y = "Incidence Rate (per 1000)",
       x = "Group") +
  theme_minimal() +
  theme(legend.position = "none")

```
```{r}
# Calculate attack rates
attack_rate_vaccine <- 8 / 17411
attack_rate_placebo <- 162 / 17511

# Calculate Vaccine Efficacy (VE)
VE <- 1 - (attack_rate_vaccine / attack_rate_placebo)
VE_percent <- round(VE * 100, 2)

# Create a table for display
VE_table <- data.frame(
  `Group` = c("BNT162b2 (Vaccine)", "Placebo", "Vaccine Efficacy"),
  `Attack Rate` = c(round(attack_rate_vaccine * 100, 3), 
                    round(attack_rate_placebo * 100, 3), 
                    paste0(VE_percent, "%"))
)

# Output the table in a formatted way
knitr::kable(VE_table, 
             caption = "Estimated Vaccine Efficacy (VE) based on observed attack rates.",
             col.names = c("Group", "Attack Rate (%)"),
             align = "c",
             booktabs = TRUE)


```

# Statistical Methods

## Model
  The experiment uses a binomial model targeting 170 infections. $\pi$, the probability measure of this model, estimates the proportion of infected individuals that had received the vaccination. Because we are using a Binomial method, we are making assumptions that should be checked. We target 170 infections, so the constant trials assumption is met. Either the infected person received the vaccine or the placebo, so the assumption of only two outcomes is met. The parameter we are estimating, $\pi$, is assumed to have some unknown true value, an assumption we cannot strictly verify, but is reasonable to believe. Lastly, we assume that our observations are independent, which we once again cannot strictly verify, but given our large sample size and the number of individuals involved in the survey, along with the fact that each participant's group was chosen randomly, this is a reasonable assumption. Thus, taking $X$ to be the number of infections out of 170 where the patient is vaccinated, our experimental model is:
  $$X \sim Bin(170, \pi)$$

  However, the parameter that we are more interested in making inference on is $\psi$, which represents the efficacy of the vaccine. This parameter is calculated as
  $$\psi = \frac{1-2\pi}{1-\pi}$$
Notably, the FDA (Food and Drug Administration) requires that in order for a drug to be released for wholesale production and use, it must be shown to have an efficacy greater than $0.3$. Thus, our hypothesis tests will test how statistically significant the evidence is that the vaccine has an efficacy greater than $0.3$.
$$H_0: \psi = 0.3;\ \ \   H_1: \psi \neq 0.3$$
We use two statistical methods to make this analysis: the frequentist maximum likelihood method, and the bayesian inference method.

## Likelihood Inference
Recall that the design of our experiment is binomial; we observe 170 infections and try to make inference on $\pi$, the proportion of infections from those who have the vaccine. Assuming each observation is independent (which we have justified above), we can write our likelihood function in terms of $\pi$:
$$L(\pi) = \binom{170}{X}(\pi)^X(1-\pi)^{170-X}$$
Where $X$ is the observed number of infections where the patient had the vaccine.


We can rewrite this likelihood function in terms of $\psi$:
$$L^*(\psi) = \binom{n}{X}\left(\frac{\psi-1}{\psi-2}\right)^X\left(\frac{-1}{\psi-2}\right)^{n-X}$$
We then find the log-likelihood function. Pictured below is the second degree Taylor approximation of the log-likelihood:

```{r log_lik_taylor, fig.width=4, fig.height=3, echo=FALSE, fig.align="center"}
psi_loglik <- function(psi){
  if(psi <= 0 || psi >= 1) return(NA_real_)
  log(choose(170, 8)) +
    8 * log((psi - 1)/(psi - 2)) -
    162 * log(2 - psi)
}

ml.binom <- maxLik2(loglik = psi_loglik, start=0.5)

 p <- plot(ml.binom) +
  labs(
    title = "2nd-Degree Taylor Approx (black) \n Exact Log-Likelihood (red)",
    x     = expression(psi),
    y     = "Log-Likelihood"
  )

psi_seq <- seq(0.7, 0.999, length.out = 300) # Choose a safe domain in (0,1)
ll_vals <- sapply(psi_seq, psi_loglik)

df_ll <- data.frame(
  psi = psi_seq,
  ll  = ll_vals
)

# 5. Overlay the exact log-likelihood in red
p + geom_line(
      data  = df_ll,
      aes(x = psi, y = ll),
      color = "red",
      size  = 1
    ) +
  coord_cartesian(xlim = c(0.9,1),ylim = c(-25, 5)) # adjust as needed to see the full curve
```
```{r log_lik_taylor2, fig.width=4, fig.height=3, echo=FALSE, fig.align="center", eval = FALSE}
psi_loglik <- function(x){
  if(x<0|x>1){
    return(NA)
  }
  return(log(choose(170,8))+8*log((x-1)/(x-2))-162*log(2-x))
}

ml.binom <- maxLik2(loglik = psi_loglik,
                    start = 0.5)

plot(ml.binom) +
  labs(title = "Second-Degree Taylor Approximation of Log-likelihood Function",
       x = expression(psi),
       y = "Log-Likelihood")
```
To maximize this likelihood function, we take the first derivative and set it equal to 0. The whole derivation, from likelihood function to final estimate formula, can be found in the Appendix. Our final formula is given by:

$$\hat{\psi}_0^{mle} = \frac{n-2X}{n-X}$$
We now perform a likelihood ratio test to test our hypotheses. We can initially find the likelihood ratio, $\Lambda$. It has formula given by:
$$\Lambda = \frac{L(\hat{\psi}_0^{mle})}{L(\psi_0^{null})}$$

Once we have calculated $\Lambda$, we can go forward with calculating $W$, which has formula given by:
$$W = 2\log(\Lambda)$$
$W$ is especially helpful for making inference, because under the null hypothesis, $W \sim \chi_1^2$. Thus, we can use the value of $W$ to find a p-value to evaluate our hypothesis, based on where it falls in the distribution of $\chi_1^2$ (we will reject the null hypothesis for large values of $W$). For reference, a plot of the chi-squared distribution with 1 degree of freedom is given in the Appendix, marked with the boundary value beyond which we reject our null hypothesis.


The asymptotic variance of \(\hat{\psi}^{\text{MLE}}\) is derived using the Fisher information of $\hat{\psi}$:
\[
I(\psi) = \frac{n}{(1 - \psi)(2 - \psi)^2},
\]
where $n$ is the sample size. We construct the Wald confidence interval as follows:
\[
\hat{\psi}^{\text{MLE}} \pm z_{\alpha/2} \cdot \frac{1}{\sqrt{n I(\hat{\psi}^{\text{MLE}})}}.
\]
This interval assumes large-sample normality of the MLE. We will derive a 95\% confidence interval using our maximum likelihood estimate (MLE).

  
\subsubsection*{Bootstrap Confidence Interval for \(\hat{\psi}_{\mathrm{MLE}}\)}

In addition to the large-sample interval, we use a computational bootstrap approach to estimate a 95\% confidence interval for \(\hat{\psi}_{\mathrm{MLE}}\). Suppose we observe $\hat{\pi} = \frac{T}{n}$ from the sample, where \(T\) is the observed number of infections out of \(n\) participants. Then:

\begin{enumerate}
    \item \textbf{Generate Resamples.} We repeatedly sample \(T^*\) from a \(\mathrm{Binomial}(n, \hat{\pi})\) distribution. For each bootstrap draw:
    \[
      \hat{\pi}^* = \frac{T^*}{n},
      \quad
      \hat{\psi}^* = \frac{1 - 2\hat{\pi}^*}{\,1 - \hat{\pi}^*}.
    \]
    
    \item \textbf{Form the Confidence Interval.} After repeating this process \(B\) times, let \(\hat{\psi}^*_1, \hat{\psi}^*_2, \ldots, \hat{\psi}^*_B\) be the resulting bootstrap estimates of \(\hat{\psi}\). We then take the 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the \(\hat{\psi}^*\) values to form the approximate 95\% confidence interval:
    \[
    \bigl[\hat{\psi}^*_{(0.025)},\; \hat{\psi}^*_{(0.975)}\bigr].
    \]

\end{enumerate}

This bootstrap procedure avoids strong distributional assumptions and can provide more reliable interval estimates for moderate sample sizes.

  
  

\subsection*{Bayesian Inference}

We can use a Bayesian approach to reanalyze the efficacy of the BNT162b2 vaccine. Let $T$ be the number of infections observed among $n$ vaccine recipients in the trial. We assume 
\[
T \mid \pi \sim \mathrm{Binomial}(n, \pi)
\]
where $\pi$ is the probability of infection in the vaccine group. As in the original trial design, vaccine efficacy (VE) is defined by Equation (1):
\[
\psi \;=\; \frac{1 - 2\pi}{\,1 - \pi\,}.
\]
Under this model, the likelihood for $T$ is proportional to $\pi^T (1-\pi)^{n-T}$.

\vspace{1em}
\noindent \textbf{Prior Specification.} We place a Beta$(a,b)$ prior on $\pi$, thereby completing a Beta--Binomial model. As reported in the original trial, the Pfizer prior was $\text{Beta}(0.700102, 1)$, while two alternative priors were elicited to achieve lower probabilities of $\psi \ge 0.3$. Specifically, these priors were chosen so that 
\[
P(\psi \ge 0.3) = 0.05 \quad \text{or} \quad 0.01,
\]
respectively. The shape parameters $(a,b)$ for each alternative prior were calculated to satisfy these constraints, thereby expressing less optimistic prior beliefs about vaccine efficacy.

\vspace{1em}
\noindent \textbf{Posterior Distribution.} With a Beta prior and a Binomial likelihood, the posterior for $\pi$ is
\[
\pi \mid T = t
\,\sim\, 
\mathrm{Beta}\bigl(a + t,\; b + n - t\bigr).
\]
Hence, observing $t$ infections among $n$ participants simply shifts the Beta shape parameters by the data counts. Posterior summaries (e.g., medians, credible intervals) for $\pi$ follow from standard Beta distribution. Once obtained, $\pi$ can be converted to $\psi$ using Equation (1).

\vspace{1em}
\noindent \textbf{Credible Intervals and Hypothesis Testing.} We report the 95\% credible interval for $\pi$, defined by the 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the posterior distribution. We similarly transform these percentiles into credible bounds for $\psi$. To assess whether $\pi < 0.5$ (equivalently, whether $\psi > 0$), we calculate
\[
p\text{-value}_{\pi} \;=\; 1 - F_\pi(0.5),
\]
where $F_\pi$ is the posterior cumulative distribution function of $\pi$. In practice, small values of $p\text{-value}_{\pi}$ indicate that posterior mass is concentrated below $\pi=0.5$, consistent with high efficacy. Parallel tests can be made on thresholds of $\psi$, such as verifying if $P(\psi > 0.3)$ exceeds a given target.




# Results

\subsubsection*{Large sample confidence interval estimate for \(\hat{\psi}\)}

Under the frequentist framework, maximum likelihood estimation (MLE) yielded a vaccine efficacy estimate of 95.0617\% (95\% confidence interval [CI]: 94.7929\%,0.953306\%).

```{r likelihood_function_plot, fig.width=4, fig.height=3, echo=FALSE, fig.align="center"}
psi_lik <- function(x){
  return(choose(170,8)*((x-1)/(x-2))^8*(-1/(x-2))^162)
}

ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
  geom_function(fun = psi_lik,
                color = "blue") +
  xlim(0.85, 1) +
  theme_bw()+
  labs(x = expression(psi),
       y = expression(L(psi)),
       title = "Likelihood Function Plotted with \nMaximizing Value Marked and Labeled")+
  geom_vline(xintercept = 154/162,
             color = "red")+
  annotate("text",
           label = paste0("MLE Estimate: ",round(154/162,6)),
           x = 0.9548,
           y = 0.05,
           angle = 270,
           color = "red")
```
When we performed a likelihood ratio test on our maximum likelihood estimate, we got the value$$W = 121.6012$$
The p-value associated with this value of $W$ is $\approx0$.
\subsubsection*{Bootstrap Interval for \(\hat{\psi}\)}

```{r, echo= FALSE}
B= 1000
set.seed(123)
n <- 160
boot_df <- replicate ( n = B, expr= (rbinom(n = 1,size = n, prob = 8/170)))
psi <- numeric(B)
for (i in 1:B){
  Tvar <- boot_df[i]
  psi[i] <- ((n-(2*Tvar)) / (n-Tvar) )
}                       

result <- quantile(psi, probs = c(0.025, 0.975))
```

Using a bootstrap procedure with \(B=1000\) resamples from a \(\mathrm{Binomial}(n, \hat{\pi})\) distribution where \(n=160\) and \(\hat{\pi}=8/170\) (from table 1), we computed \(\hat{\psi}\) in each resample. The 2.5\textsuperscript{th} and 97.5\textsuperscript{th} percentiles of the resulting bootstrap distribution of \(\hat{\psi}\) define the approximate 95\% confidence interval. Table~\ref{tab:bootstrap-interval} shows the interval endpoints based on this approach.

\begin{table}[h]
\centering
\caption{Bootstrap 95\% Confidence Interval for \(\hat{\psi}\)}
\label{tab:bootstrap-interval}
\begin{tabular}{lc}
\hline
Lower (2.5\%) & `r round(result[1],4)` \\
Upper (97.5\%) & `r round(result[2],4)` \\
\hline
\end{tabular}
\end{table}






  
\subsubsection*{Bayesian Results}



```{r, echo = FALSE}
library(LearnBayes)
prior1Beta <- beta.select(quantile1 = list(p=0.05, x = 7/17),
            quantile2 = list(p = 0.5, x = 0.5))
prior2Beta <- beta.select(quantile1 = list(p=0.01, x = 7/17),
            quantile2 = list(p = 0.5, x = 0.5))
```

```{r fig.width=4, fig.height=3, echo=FALSE, fig.align="center"}

ggplot() +
geom_function(fun = psi_dist,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102, shape2 = 1),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102 + 8, shape2 = 162 + 1),
xlim=c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04, shape2 = 43.04),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04 + 8, shape2 = 162 + 43.04),
xlim=c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63, shape2 = 85.63),
xlim = c(0,1)) +
geom_function(fun = psi_dist,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63 + 8, shape2 = 162 + 85.63),
xlim=c(0,1)) +
scale_color_manual(name = "dist", 
                   values = c("Pfizer" = "blue", "0.05" = "red", "0.01" = "black"))+
labs(title = "Prior and Posterior Distributions",
x=expression(pi),
y = "PDF")


```

```{r , echo = FALSE}
# Pfizer Posterior
pfizer_shape1 <- 0.700102 + 8
pfizer_shape2 <- 162 + 1
pfizer_median <- qbeta(0.5, shape1 = pfizer_shape1, shape2 = pfizer_shape2)
pfizer_ci <- qbeta(c(0.025, 0.975), shape1 = pfizer_shape1, shape2 = pfizer_shape2)

# 0.05 Prior Posterior
prior1_shape1 <- prior1Beta + 8
prior1_shape2 <- 162 + prior1Beta
prior1_median <- qbeta(0.5, shape1 = prior1_shape1, shape2 = prior1_shape2)
prior1_ci <- qbeta(c(0.025, 0.975), shape1 = prior1_shape1, shape2 = prior1_shape2)

# 0.01 Prior Posterior
prior2_shape1 <- prior2Beta + 8
prior2_shape2 <- 162 + prior2Beta
prior2_median <- qbeta(0.5, shape1 = prior2_shape1, shape2 = prior2_shape2)
prior2_ci <- qbeta(c(0.025, 0.975), shape1 = prior2_shape1, shape2 = prior2_shape2)



# Approximate median for psi
pfizer_median_psi   <- psi_transform(pfizer_median)
prior1_median_psi   <- psi_transform(prior1_median)
prior2_median_psi   <- psi_transform(prior2_median)

# Approximate endpoints for psi
pfizer_ci_psi       <- psi_transform(pfizer_ci)
prior1_ci_psi       <- psi_transform(prior1_ci)
prior2_ci_psi       <- psi_transform(prior2_ci)



# The threshold for pi at which psi = 0.3
pi_threshold_for_psi_0.3 <- pi_transform(0.3)

# Probability that pi >= 0.4117647
p_psi_pfizer <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = pfizer_shape1,
                          shape2 = pfizer_shape2)

p_psi_prior1 <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = prior1_shape1,
                          shape2 = prior1_shape2)

p_psi_prior2 <- 1 - pbeta(pi_threshold_for_psi_0.3,
                          shape1 = prior2_shape1,
                          shape2 = prior2_shape2)

```
\begin{figure}[h]
\centering
% (Placeholder for your posted code that generates prior-compare plot)
\caption{Comparison of the three priors (Pfizer, 0.05, 0.01) and their corresponding posteriors for $\psi$.}
\label{fig:posterior-compare}
\end{figure}

\vspace{1em}
\noindent \textbf{Posterior Summaries (for \(\psi\)).}
Table~\ref{tab:bayes-posterior-psi} presents the \textit{approximate} posterior medians and 95\% credible intervals for \(\psi\) under each prior (calculated by transforming the corresponding values for \(\pi\)).

\begin{table}[h]
\centering
\caption{Approximate posterior medians and 95\% credible intervals for $\psi$ under each prior.}
\label{tab:bayes-posterior-psi}
\begin{tabular}{lcc}
\hline
\textbf{Prior} & \textbf{Posterior Median} & \textbf{95\% Credible Interval (Approx)} \\
\hline
Pfizer 
 & $`r round(pfizer_median_psi,4)`$ 
 & [$`r round(pfizer_ci_psi[2],4)`$, $`r round(pfizer_ci_psi[1],4)`$] \\
0.05   
 & $`r round(prior1_median_psi[1],4)`$ 
 & [$`r round(prior1_ci_psi[2],4)`$, $`r round(prior1_ci_psi[1],4)`$] \\
0.01   
 & $`r round(prior2_median_psi[1],4)`$ 
 & [$`r round(prior2_ci_psi[2],4)`$, $`r round(prior2_ci_psi[1],4)`$] \\
\hline
\end{tabular}
\end{table}

\vspace{1em}
\noindent \textbf{Hypothesis Testing (for \(\psi\)).}
For each posterior, we computed the probability \(P(\psi \le 0.3)\), which serves as a Bayesian p-value under the hypothesis 
\[
H_0: \psi \le 0.3 
\quad \text{vs.} \quad 
H_1: \psi > 0.3.
\]
(This threshold can be changed as needed, depending on your target efficacy.) Table~\ref{tab:bayes-hypothesis-psi} shows these values. We define
\[
p\text{-value} = P(\psi \le 0.3),
\]
where \(F_\psi\) is the posterior cumulative distribution function of \(\psi\). The estimated Bayesian p-values for each prior are:

\begin{table}[h]
\centering
\caption{Bayesian p-values for testing $H_0: \psi \le 0.3$ under each posterior.}
\label{tab:bayes-hypothesis-psi}
\begin{tabular}{lc}
\hline
\textbf{Prior} & \textbf{Bayesian p-value} \\
\hline
Pfizer   & $`r round(p_psi_pfizer,4)`$ \\
0.05     & $`r round(p_psi_prior1,4)`$ \\
0.01     & $`r round(p_psi_prior2,4)`$ \\
\hline
\end{tabular}
\end{table}


\subsection*{Discussion and Conclusion}

\subsection*{Frequentist Maximum Likelihood Anaylsis}

The frequentist maximum likelihood estimation yields an estimate of 0.9506, which is significantly higher than the value we are testing against, 0.3. In testing the statistical significance of this result, the likelihood ratio test obtains the value $W = 121.6012$. Considering under the null hypothesis, $W\sim\chi_1^2$, which has expected value 1 and variance 2, this value is extraordinarily high, and it is thus no surprise that we get a p-value that approximates 0. Interestingly, because the p-value is so low, we could declare any value less than 0.906 for minimum baseline efficacy and our data would still constitute statistically significant evidence at the significance level of $\alpha = 0.05$ that the vaccine's efficacy is higher (See Appendix for plot). We thus reject the null hypothesis that the true value of our parameter $\psi$ is equal to $0.3$. This is right in line with the results achieved by the large sample confidence interval, as well as the results yielded by the bayesian analysis. 

The frequentist analysis produced a 95\% confidence interval for vaccine efficacy of (0.947929,0.953306), indicating that, with repeated sampling, 95\% of such intervals would contain the true efficacy. This interval corresponds to the estimated efficacy of 95.0\% (95\% CI: 94.8\%, 95.3\%), which aligns closely with the efficacy reported in the original Pfizer-BioNTech trial (95\% CI: 90.3\%, 97.6\%). However, the narrower interval obtained here reflects the large-sample properties of the Wald method, which uss Fisher information for variance estimation.

The interval's precision is a strength of the frequentist approach, as the large sample size (\(n = 34922\)) justifies the use of asymptotic normality assumptions. While the interval excludes values below 94.8\%, providing strong evidence against low efficacy (\(\psi \leq 30\%\)), its upper bound (95.3\%) is more conservative than the Bayesian credible interval (97.6\%). This discrepancy highlights methodological differences: frequentist intervals quantify long-run coverage probability, whereas Bayesian intervals represent posterior belief.

Thus, our frequentist analysis constitutes statistically significant evidence that the vaccine efficacy is quite high, just as Pfizer orignally suggested.

\subsection*{Bootstrap}

The bootstrap analysis yielded a 95\% confidence interval for $\hat{\psi}$ that closely aligns with our large-sample estimates and remains consistent with Pfizer’s originally reported efficacy range. By resampling from a $\mathrm{Binomial}(n, \hat{\pi})$ distribution, the bootstrap circumvents any strong assumptions about the distribution of $\hat{\psi}$ (beyond the binomial sampling model). This robustness adds credibility to our inference, especially in moderately sized samples where asymptotic approximations can be less reliable.

Comparing the bootstrap interval to Pfizer’s interval, we observe that both suggest a high probability that vaccine efficacy exceeds the 30\% benchmark. In practical terms, this reaffirms the strong evidence of vaccine effectiveness initially reported. Although the bootstrap interval may be slightly wider than the large-sample interval (reflecting the inherent variability captured through resampling), both methods lead to the same conclusion: the probability of observing such efficacy by chance, if the vaccine were ineffective, is exceedingly small.

Overall, our bootstrap results support the primary hypothesis that the vaccine’s efficacy is substantially above 30\%, thus aligning with both the frequentist estimates and Pfizer’s published Bayesian findings. This convergence of evidence across multiple analytic strategies enhances confidence in the robustness of our conclusions regarding BNT162b2 efficacy.


\subsection*{Bayesian}

Our Bayesian analysis provides consistent evidence that the vaccine efficacy \(\psi\) remains high. As shown in \textbf{Figure~2}, updating the Pfizer prior \(\mathrm{Beta}(0.700102,1)\) and two alternative priors \(\mathrm{Beta}(43.04,43.04)\) and \(\mathrm{Beta}(85.63,85.63)\) with the observed data \((t=8,\, n=170)\) yields posterior distributions for \(\psi\) that are heavily skewed toward large efficacy values.

\textbf{Table~3} details the approximate numerical results for \(\psi\). Even though the alternative priors initially place more mass around intermediate efficacy, the data strongly pull the posterior medians upward.

Although the alternative priors shift the posterior to moderately lower efficacy, the observed infection count (only 8 out of 170) still imposes a high central estimate for \(\psi\). This suggests that once sufficient data are incorporated, the final posterior distribution is relatively robust to prior differences.

Finally, \textbf{Table~4} presents Bayesian p-values for testing a clinically relevant hypothesis such as \(H_0: \psi \le 0.3\). For all three priors, \(P(\psi \le 0.3)\) is effectively zero, implying near-certain rejection of \(H_0\). This finding aligns with the frequentist conclusion of strong efficacy, further bolstering overall confidence in the result.

Overall, the Bayesian framework yields direct probability statements about clinically meaningful thresholds (e.g., \(\psi>0.3\)). Given sufficiently informative data, the resulting posterior estimates remain consistent across varying prior beliefs. These results corroborate Pfizer’s original analysis, highlighting that BNT162b2 efficacy remains high across a range of reasonable priors.

# Bibliography

Baden, L.R., et al. (2021). \textit{N. Engl. J. Med.}, 384(5), 403–416.

Berry, D.A. (2006). \textit{Nature}, 440(7088), 1078–1083.

U.S. Food \& Drug Administration (2020). Emergency Use Authorization for Pfizer-BioNTech COVID-19 Vaccine.

Polack, F.P., et al. (2020). \textit{N. Engl. J. Med.}, 383(27), 2603–2615.

Wasserstein, R.L., et al. (2019). \textit{Am. Stat.}, 73(sup1), 1–19.

# Appendix

## Code
```{r ref.label = "important_R_code", eval=FALSE}
```

```{r ref.label = "psi_dist", eval=FALSE }
psi_dist <- function(x, shape1, shape2){
  pi <- (x-1)/(x-2)
  return(dbeta(x = pi, shape1 = shape1, shape2 = shape2))
}
```

```{r re.label = "transform pi to psi and reverse", eval = FALSE}
pi_transform <- function(psi_val) {
  (psi_val - 1) / (psi_val - 2)
}

# Define the transformation function
psi_transform <- function(pi_val) {
  (1 - 2 * pi_val) / (1 - pi_val)
}
```


## Plots

```{r, echo=FALSE}
ggplot() +
  geom_function(fun = psi_dist,
                mapping = aes(color = "Pfizer"),
                args = list(shape1 = 0.700102, shape2 = 1),
                xlim = c(0, 1)) +
  geom_function(fun = psi_dist,
                mapping = aes(color = "prior1"),
                args = list(shape1 = 43.04, shape2 = 43.04),
                xlim = c(0, 1)) +
  geom_function(fun = psi_dist,
                mapping = aes(color = "prior2"),
                args = list(shape1 = 85.63, shape2 = 85.63),
                xlim = c(0, 1)) +
  scale_color_manual(name = "dist", 
                     values = c("Pfizer" = "blue", "prior1" = "red", "prior2" = "black")) +
  labs(title = "Prior Distributions", x = expression(pi), y = "PDF")
```

```{r, echo = FALSE}

ggplot() +
geom_function(fun = dbeta,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102, shape2 = 1),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "Pfizer"),
args = list(shape1 = 0.700102 + 8, shape2 = 162 + 1),
xlim=c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04, shape2 = 43.04),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.05"),
args = list(shape1 = 43.04 + 8, shape2 = 162 + 43.04),
xlim=c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63, shape2 = 85.63),
xlim = c(0,1)) +
geom_function(fun = dbeta,
mapping = aes(color = "0.01"),
args = list(shape1 = 85.63 + 8, shape2 = 162 + 85.63),
xlim=c(0,1)) +
scale_color_manual(name = "dist", 
                   values = c("Pfizer" = "blue", "0.05" = "red", "0.01" = "black"))+
labs(title = "Priors and Posteriors",
x=expression(pi),
y = "PDF")


```

```{r, echo = FALSE}
ggplot()+
  stat_function(fun = dchisq,
                args = list(df=1),
                color = "black")+
  geom_vline(xintercept = qchisq(p=0.95,
                                 df=1),
             color = "red")+
  theme_bw()+
  labs(x = expression(x),
       y = expression(f(x)),
       title = "Chi-Squared PDF with Upper Boundary Marked for \n a Significance Level of 0.05")+
  xlim(0,4) +
  annotate("text",
           label = paste("Acceptance boundary: x =",
                         round(qchisq(df=1,
                                      p=0.95),
                               3)),
           x=qchisq(p=0.95,df=1)-0.1,
           y=1,
           angle = 90,
           color = "red",
           size = 4)+
  annotate("text",
           label = expression(chi[1]^2),
           x = 0.20,
           y = 1.75)
          
```

```{r, echo = FALSE}
pval_null <- function(x){
  return(1 - pchisq(df = 1,
                    q = 16*log(((154/162)-1)/(x-1))+340*log((x-2)/((154/162)-2))))
}

upp_val <- uniroot(f = function(x){pval_null(x)-0.05}, 
                   lower = 0.5,
                   upper = 0.95)

ggplot()+
  geom_function(fun = pval_null,
                color = "black")+
  xlim(0,0.91)+
  geom_hline(yintercept = 0.05,
             color = "red",
             linetype = 2)+
  geom_vline(xintercept = 0.3,
             color = "blue",
             linetype = 2)+
  geom_vline(xintercept = upp_val$root,
             color = "darkblue",
             linetype =2)+
  annotate("text",
           label = "Significance level 0.05",
           x = 0.1,
           y = 0.052,
           color = "red")+
  annotate("text",
           label = "Initial null value: 0.3",
           x = 0.315,
           y = 0.03,
           angle = 270,
           color = "blue")+
  annotate("text",
           label = "Highest null value below 0.05: 0.9061",
           x = 0.695,
           y = 0.0485,
           color = "darkblue")+
  theme_bw()+
  labs(x = "Null value",
       y = "P-value",
       title = "Potential Null Value vs. Calculated P-value")
```
This yields that if our null value were to change, our data would still constitute statistically significant evidence at a significance level 0.05 sufficent to reject the null hypothesis.

## Proofs

Dericvation of the Maximum Likelihood Estimator for $\widehat{\psi}_0^{mle}$:

We can begin with our Likelihood function
$$L(\pi) = \binom{n}{X}(\pi)^X(1-\pi)^{170-X}$$
Where $x$ is the observed number of infections where the patient had the vaccine.
Notably, however, we are not hoping to draw inference on $\pi$, but rather on $\psi$, the efficacy of the vaccine. We can write this parameter in terms of $\pi$.
$$\psi = \frac{1-2\pi}{1-\pi}$$
In order to write our Likelihood function in terms of $\psi$, we can rewrite $\psi$ in terms of $\pi$:
$$\pi = \frac{\psi - 1}{\psi -2}$$
Now we rewrite our likelihood function.
$$L^*(\psi) = \binom{n}{X}\left(\frac{\psi-1}{\psi-2}\right)^X\left(\frac{-1}{\psi-2}\right)^{n-X}$$
Now that we have written our full likelihood function in terms of $\psi$, we can write the log likelihood function.
$$\ell^*(\psi) = \log\binom{n}{X}+X\log(\psi-1)-X\log(\psi-2)-(n-X)\log(\psi-2) +(n-X)\log(-1)$$
$$\ell^*(\psi) =  \log\left(\binom{n}{X}(-1)^{n-X}\right)+X\log(\psi-1)-n\log(\psi-2)$$
To maximize this equation, we take its derivative with respect to $\psi$:
$$\frac{d}{d\psi}\ell^*(\psi) = \frac{X}{\psi-1} - \frac{n}{\psi-2}$$
Setting this derivative finds the maximum:
$$0 = \frac{X}{\hat{\psi}_0^{mle} - 1} - \frac{n}{\hat{\psi}_0^{mle}-2}$$
$$\frac{n}{\hat{\psi}_0^{mle}-2} = \frac{X}{\hat{\psi}_0^{mle}-1}$$
$$n\hat{\psi}_0^{mle} - n = X\hat{\psi}_0^{mle} - 2X$$
$$(n-X)\hat{\psi}_0^{mle} = n-2X$$
$$\hat{\psi}_0^{mle} = \frac{n-2X}{n-X}$$

Derivation of Likelihood Ratio Test Value:

Recall that when performing a hypothesis test for a maximum likelihood estimator, we are interested in calculating $W$, which is given by
$$W = 2\ln\left[\frac{L(\hat{\psi}_0^{mle})}{L(\psi_0^{null})}\right]$$
The log of the ratio of two likelihoods is equal to the difference of their respective log-likelihoods:
$$W = 2\left(\ell(\hat{\psi}_0^{mle}) - \ell(\psi_0^{null})\right)$$
$$\ell^*(\psi) =  \log\left(\binom{n}{X}(-1)^{n-X}\right)+X\log(\psi-1)-n\log(\psi-2)$$
$$W = 2\left(\left(\log\left(\binom{n}{X}(-1)^{n-X}\right)+X\log(\hat{\psi}_0^{mle}-1) - n\log(\hat{\psi}_0^{mle}-2)\right) - \left(\log\left(\binom{n}{X}(-1)^{n-X}\right)+X\log(\psi_0^{null}-1) - n\log(\psi_0^{null}-2)\right)\right)$$
$$W = 2\left(\left(X\log(\hat{\psi}_0^{mle}-1) - n\log(\hat{\psi}_0^{mle}-2)\right) - \left(X\log(\psi_0^{null}-1) - n\log(\psi_0^{null}-2)\right)\right)$$
$$W= 2\left(X\log\left(\frac{\hat{\psi}_0^{mle}-1}{\psi_0^{null}-1}\right) + n\log\left(\frac{\psi_0^{null}-2}{\hat{\psi}_0^{mle}-2}\right)\right)$$
$$W= 2X\log\left(\frac{\hat{\psi}_0^{mle}-1}{\psi_0^{null}-1}\right) + 2n\log\left(\frac{\psi_0^{null}-2}{\hat{\psi}_0^{mle}-2}\right)$$



Derivation of the Large Sample Confidence Interval:

As calculated above, our likelihood function is given by
$$\ell(\psi) = \log\binom{170}{8}+8\log(\psi-1)-8\log(\psi-2)-162\log(\psi-2) +162\log(-1)$$

Taking the derivative with respect to \( \psi \),

\[
\frac{d}{d\psi} \ell(\psi) = \frac{8}{\psi-1} - \frac{170}{\psi-2}
\]

And the second derivative is

\[\frac{d^2}{d\psi^2}\ell(\psi) = -\frac{8}{(\psi -1)^2} + \frac{170}{(\psi -2)^2}\]
The Fisher information is the negative expectation of the second derivative of the log-likelihood. So for $X \sim \text{Binomial}(n, \pi)$,

\[
I(\psi) = \mathbb{E}\left[-\frac{d^2\ell}{d\psi^2}\right] = \frac{\mathbb{E}[X]}{(1 - \psi)^2} - \frac{n}{(2 - \psi)^2}.
\]

Substituting $\mathbb{E}[X] = n\pi = n \cdot \frac{1 - \psi}{2 - \psi}$,

\[
I(\psi) = \frac{n(1 - \psi)}{(2 - \psi)(1 - \psi)^2} - \frac{n}{(2 - \psi)^2} = \frac{n}{(2 - \psi)(1 - \psi)} - \frac{n}{(2 - \psi)^2}.
\]

Factoring out $\frac{n}{2 - \psi}$,

\[
I(\psi) = \frac{n}{2 - \psi} \left(\frac{1}{1 - \psi} - \frac{1}{2 - \psi}\right).
\]

Combining terms with a common denominator,

\[
I(\psi) = \frac{n}{2 - \psi} \cdot \frac{(2 - \psi) - (1 - \psi)}{(1 - \psi)(2 - \psi)} = \frac{n}{(1 - \psi)(2 - \psi)^2}.
\]

So we get 
\[
I(\psi) = \frac{n}{(1 - \psi)(2 - \psi)^2}.
\]

We know that our large sample confidence interval is given by \[
\hat{\psi}^{mle} \pm z_{\alpha/2}\cdot \frac{1}{\sqrt{n I(\hat{\psi})}}\]

We may now plug in our estimates and the given parameters such as sample size and significance level.
